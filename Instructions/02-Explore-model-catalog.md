---
lab:
  title: 言語モデルを選択してデプロイする
  description: 生成 AI アプリケーションは、1 つ以上の言語モデルに基づいて構築されます。 自分の生成 AI プロジェクトに適したモデルを見つけて選択する方法について説明します。
---

# 言語モデルを選択してデプロイする

Azure AI Foundry のモデル カタログは、さまざまなモデルを試してから使用できる中央リポジトリとして機能し、生成 AI シナリオの作成を容易にします。

この演習では、Azure AI Foundry ポータルでモデル カタログを調べて、問題の解決に役立つ生成 AI アプリケーション用に使用可能なモデルを比較します。

この演習には、約 **25** 分かかります。

## Azure AI ハブとプロジェクトを作成する

Azure AI ハブは、1 つ以上の "プロジェクト" を定義できる共同作業用のワークスペースとして機能します。** プロジェクトと Azure AI ハブを作成してみましょう。

1. Web ブラウザーで [Azure AI Foundry ポータル](https://ai.azure.com) (`https://ai.azure.com`) を開き、Azure 資格情報を使用してサインインします。 初めてサインインするときに開いたヒントまたはクイック スタート ウィンドウを閉じます。また、必要に応じて左上にある **Azure AI Foundry** ロゴを使用してホーム ページに移動します。それは次の画像のようになります。

    ![Azure AI Foundry ポータルのスクリーンショット。](./media/ai-foundry-home.png)

1. ホーム ページで、**[+ 作成]** を選択します。
1. **[プロジェクトの作成]** ウィザードで、適切なプロジェクト名 (`my-ai-project` など) を入力し、既存のハブが推奨された場合は新しいハブを作成するオプションを選択します。 次に、ハブとプロジェクトをサポートするために自動的に作成される Azure リソースを確認します。
1. **[カスタマイズ]** を選択し、ハブに次の設定を指定します。
    - **[ハブ名]**: *一意の名前 - たとえば `my-ai-hub`*
    - **[サブスクリプション]**:"*ご自身の Azure サブスクリプション*"
    - **[リソース グループ]**: *一意の名前 (たとえば、`my-ai-resources`) で新しいリソース グループを作成するか、既存のものを選びます*
    - **場所**: **[選択に関するヘルプ]** を選択し、次に [場所ヘルパー] ウィンドウで **gpt-4** を選択し、推奨されるリージョンを選択します\*
    - **Azure AI サービスまたは Azure OpenAI の接続**: *適切な名前 (たとえば、`my-ai-services`) を使用して新しい AI サービス リソースを作成するか、既存のものを使用します*
    - **Azure AI 検索への接続**:接続をスキップする

    > \* モデルのクォータは、リージョンのクォータによってテナント レベルで制限されます。 演習の後半でクォータ制限に達した場合は、別のリージョンに別のリソースを作成する必要が生じる可能性があります。

1. **[次へ]** を選択し、構成を確認します。 **[作成]** を選択し、プロセスが完了するまで待ちます。
1. プロジェクトが作成されたら、表示されているヒントをすべて閉じて、Azure AI Foundry ポータルのプロジェクト ページを確認します。これは次の画像のようになっているはずです。

    ![Azure AI Foundry ポータルの Azure AI プロジェクトの詳細のスクリーンショット。](./media/ai-foundry-project.png)

## Azure AI 推論サービスのデプロイを構成する

Azure AI Foundry ポータルでモデルをデプロイするには、複数のオプションがあります。 この演習では、Azure AI Foundry モデル カタログの *Azure OpenAI* モデルと *Model as a service* モデルの両方をサポートする **Azure AI モデル推論** デプロイ オプションを使用します。 すべてのモデルは Azure AI サービス リソースによってホストされている共通エンドポイントにデプロイされるため、動作とパフォーマンスを比較するために、モデルをテストするときに簡単にモデルを切り替えることができます。

1. Azure AI Foundry プロジェクト ページの右上にあるツール バーで、**[プレビュー機能]** アイコン (📣) を使用してプレビュー機能を表示します。
1. **[Azure AI モデル推論サービスにモデルをデプロイする]** 機能が有効になっていることを確認します。 次に、**プレビュー機能**ウィンドウを閉じます。

## モデルの詳細とベンチマークを確認する

モデルの選択を助けるために、モデルの説明とベンチマークを調べて、どのモデルがニーズに最も適しているかを判断できます。

1. Azure AI Foundry プロジェクト ポータルの左側のナビゲーション ウィンドウで **[モデル カタログ]** を選択します。
1. モデル カタログ のホーム ページで、`gpt-4` を検索して、**GPT-4** チャット完了モデルを見つけます。

    ![モデル カタログ内の "GPT-4" の検索のスクリーンショット。](./media/model-catalog-search-gpt4.png)

1. **GPT-4** モデルを選択して、その詳細を表示します。 説明を読み、ページで使用可能なその他の情報を確認します。

    ![GPT-4 モデルの詳細ページのスクリーンショット。](./media/gpt4-details.png)

1. **GPT-4** ページで、**[ベンチマーク]** タブを表示して、一部の標準パフォーマンス ベンチマークと同様のシナリオで使用されている他のモデルとのモデルの比較を確認します。

    ![GPT-4 の [モデル ベンチマーク] ページのスクリーンショット。](./media/gpt4-benchmarks.png)

1. **GPT-4** ページ タイトルの横にある戻る矢印 (**&larr;**) を使用して、モデル カタログのホーム ページに戻ります。
1. モデル カタログで、`Phi-3.5-mini-instruct` を検索し、**Phi-3.5-mini-instruct** モデルの詳細とベンチマークを表示します。

## モデルの比較

2 つの異なるモデルを確認しました。どちらも、生成 AI チャット アプリケーションの実装に使用できます。 次に、これら 2 つのモデルのメトリックを視覚的に比較してみましょう。

1. **モデル カタログ**のホームページに戻ります。
1. **[モデルの比較]** を選択します。 モデル比較用のビジュアル チャートが、一般的なモデルの選択と共に表示されます。

    ![モデル比較ページのスクリーンショット。](./media/compare-models.png)

1. 左側の **[比較するモデル]** ウィンドウで、*質問応答*などの一般的なタスクを選択して、特定のタスクで一般的に使用されるモデルを自動的に選択できることに注意してください。
1. **[すべてのモデルをクリア]** (&128465;) アイコンを使用して、事前に選択したすべてのモデルを削除します。
1. **[+ 比較するモデル]** ボタンを使用して、**GPT-4** モデルを一覧に追加します。 次に、同じボタンを使用して、**Phi-3.5-mini-instruct** モデルを一覧に追加します。
1. **品質インデックス** (モデルの品質を示す標準化されたスコア) と**コスト**に基づいてモデルを比較しているチャートを確認します。 チャート内でモデルを表すポイントの上にマウスを合わせると、モデルの特定の値を確認できます。

    ![GPT-4 と Phi-3.5-mini-instruct のモデル比較チャートのスクリーンショット。](./media/comparison-chart.png)

1. **X 軸**ドロップダウン メニューの **[品質]** で、次のメトリックを選択し、結果の各グラフを観察してから次に切り替えます。
    - 精度
    - 一貫性
    - 流暢性
    - 関連性

## モデルを展開する

モデル ベンチマークを使用したオプションを見てきたので、言語モデルをデプロイする準備ができました。 モデル カタログを参照してそこからデプロイすることも、**[デプロイ]** ページを使用してモデルをデプロイすることもできます。 両方のオプションを見てみましょう。

### *モデル カタログ*からモデルをデプロイする

まず、モデル カタログからモデルをデプロイします。 使用可能な複数のモデルを確認する場合には、このオプションが好ましい場合があります。

1. **モデル カタログ**のホームページに戻ります。
1. 前に行ったように、`gpt-4` モデルを検索して選択します。
1. **GPT-4** ページで、**[デプロイ]** を選択し、デプロイの詳細で **[カスタマイズ]** を選択して、以下の設定でモデルをデプロイします。
1. デプロイの詳細で **[カスタマイズ]** を選択して、以下の設定でモデルをデプロイします。
    - **デプロイ名**: *モデル デプロイの一意の名前 (たとえば `gpt-4`)*
    - **デプロイの種類**:Standard
    - **モデル バージョン**: 0613
    - **接続されている AI リソース**: *使用している Azure OpenAI リソース接続を選択します*
    - **1 分あたりのトークン数のレート制限 (1,000 単位)**:5,000
    - **コンテンツ フィルター**: DefaultV2
    - **動的クォータを有効にする**: 無効
      
    > **注**:TPM を減らすと、ご利用のサブスクリプション内で使用可能なクォータが過剰に消費されることを回避するのに役立ちます。 この演習で使用するデータには、5,000 TPM で十分です。

1. デプロイが完了するまで待ちます。

### *モデル + エンドポイント*を使用してモデルをデプロイする

デプロイするモデルが既にわかっている場合は、**[モデル + エンドポイント]** でそれを行うことができます。

1. 左側のナビゲーション バーの **[マイ アセット]** セクションで、**[モデル + エンドポイント]** を選択します。
1. **[モデル デプロイ]** タブの **[+ モデルのデプロイ]** ドロップダウン リストで、**[基本モデルのデプロイ]** を選択します。 次に、`Phi-3.5-mini-instruct` を検索して選択を確認します。
1. モデル ライセンスに同意します。
1. 次の設定で **Phi-3.5-mini-instruct** モデルをデプロイします。
    - **デプロイ名**: *モデル デプロイの一意の名前 - たとえば、`Phi-3.5-mini-instruct`*
    - **デプロイの種類**: グローバル標準
    - **デプロイの詳細**: *既定の設定を使用します*

1. デプロイが完了するまで待ちます。

## チャット プレイグラウンドでモデルをテストする

比較できるモデルが 2 つあるので、対話的操作でモデルがどのように動作するかを見てみましょう。

### チャットの準備をする

1. ナビゲーション バーで、**[プレイグラウンド]** を選択します。 次に、**[チャット プレイグラウンド]** を選択します。
1. **[セットアップ]** ウィンドウの **[モデルの指示とコンテキストを指定する]** フィールドで、システム プロンプトを `You are an AI assistant that helps solve problems.` に設定します
1. **[変更の適用]** を選択します。

### *GPT-4* モデルとチャットする

**[セットアップ]** ウィンドウで、*GPT-4* モデルを選択します。
1. チャット ウィンドウに次のクエリを入力します

    ```
    I have a fox, a chicken, and a bag of grain that I need to take over a river in a boat. I can only take one thing at a time. If I leave the chicken and the grain unattended, the chicken will eat the grain. If I leave the fox and the chicken unattended, the fox will eat the chicken. How can I get all three things across the river without anything being eaten?
    ```

1. 応答を表示します。 それから、次のフォローアップ クエリを入力します。

    ```
    Explain your reasoning.
    ```

### *Phi-3.5* モデルとチャットする

1. **[セットアップ]** ウィンドウで、*Phi-3.5* モデルを選択します。
1. GPT-4 モデルのテストに使用したのと同じプロンプトを繰り返す前に、新しいチャット セッションが開始されていることを確認します。
1. チャット ウィンドウに次のクエリを入力します

    ```
    I have a fox, a chicken, and a bag of grain that I need to take over a river in a boat. I can only take one thing at a time. If I leave the chicken and the grain unattended, the chicken will eat the grain. If I leave the fox and the chicken unattended, the fox will eat the chicken. How can I get all three things across the river without anything being eaten?
    ```

1. 応答を表示します。 それから、次のフォローアップ クエリを入力します。

    ```
    Explain your reasoning.
    ```

### さらに比較を実行する

1. 両方のモデルで次のパズルを試してみてください。モデルに推論を説明するよう求めます (正解は 40 です)。

    ```
    I have 53 socks in my drawer: 21 identical blue, 15 identical black and 17 identical red. The lights are out, and it is completely dark. How many socks must I take out to make 100 percent certain I have at least one pair of black socks?
    ```

## モデルについて熟考する

2 つのモデルを比較しました。それらは、適切な応答を生成する能力とコストの両方の点で異なる場合があります。 どのような生成シナリオでも、実行する必要があるタスクの適合性と、処理する必要がある要求の数に対して、モデルを使用するコストのバランスが適切なモデルを見つける必要があります。

モデル カタログで提供される詳細やベンチマークと、モデルを視覚的に比較する能力は、生成 AI ソリューションの候補モデルを特定する際の出発点として役立ちます。 その後、チャット プレイグラウンドでさまざまなシステム プロンプトとユーザー プロンプトを使用して候補モデルをテストできます。

## クリーンアップ

Azure AI Foundry ポータルを確認し終わったら、不要な Azure コストが発生しないように、この演習で作成したリソースを削除する必要があります。

1. [Azure ポータル](https://portal.azure.com)を開き、この演習で使用したリソースをデプロイしたリソース グループの内容を表示します。
1. ツール バーの **[リソース グループの削除]** を選びます。
1. リソース グループ名を入力し、削除することを確認します。
