---
lab:
  title: 独自のデータを使用する生成 AI アプリを作成する
  description: 検索拡張生成 (RAG) モデルを使用して、独自のデータを使ってプロンプトをグラウンディングするチャット アプリを構築する方法について説明します。
---

# 独自のデータを使用する生成 AI アプリを作成する

取得拡張生成 (RAG) は、カスタム データ ソースからのデータを、生成 AI モデルのプロンプトに統合するアプリケーションを構築するために使用される手法です。 RAG は、生成 AI アプリを開発するために一般的に使用されるパターンです。チャット ベースのアプリケーションでは、言語モデルを使用して入力を解釈し、適切な応答を生成します。

この演習では Azure AI Foundry ポータル、Azure AI Foundry SDK および Azure OpenAI SDK を使用して、カスタム データを生成 AI アプリに統合します。

この演習は約 **45** 分かかります。

> **注**: この演習は、変更される可能性があるプレリリース SDK に基づいています。 必要に応じて、特定のバージョンのパッケージを使用しました。利用可能な最新バージョンが反映されていない可能性があります。

## Azure AI Foundry プロジェクトを作成する

まず、Azure AI Foundry プロジェクトと、独自のデータ (Azure AI 検索リソースを含む) の使用をサポートするために必要なサービス リソースを作成します。

1. Web ブラウザーで [Azure AI Foundry ポータル](https://ai.azure.com) (`https://ai.azure.com`) を開き、Azure 資格情報を使用してサインインします。 初めてサインインするときに開いたヒントまたはクイック スタート ウィンドウを閉じます。また、必要に応じて左上にある **Azure AI Foundry** ロゴを使用してホーム ページに移動します。それは次の画像のようになります。

    ![Azure AI Foundry ポータルのスクリーンショット。](./media/ai-foundry-home.png)

1. ホーム ページで、**[+ 作成]** を選択します。
1. **[プロジェクトの作成]** ウィザードで、有効なプロジェクト名を入力し、既存のハブが推奨された場合は、新しいハブを作成するオプションを選択します。 次に、ハブとプロジェクトをサポートするために自動的に作成される Azure リソースを確認します。
1. **[カスタマイズ]** を選択し、ハブに次の設定を指定します。
    - **ハブ名**: *ハブの有効な名前*
    - **[サブスクリプション]**:"*ご自身の Azure サブスクリプション*"
    - **リソース グループ**: *リソース グループを作成または選択します。*
    - **場所**: **[選択に関するヘルプ]** を選択し、次に [場所ヘルパー] ウィンドウで **GPT-4** を選択し、推奨されるリージョンを選択します\*
    - **Azure AI サービスまたは Azure OpenAI への接続**: *新しい AI サービス リソースを作成します*
    - **Azure AI 検索の接続**: *一意の名前で新しい Azure AI 検索リソースを作成する*

    > \* Azure OpenAI リソースは、リージョンのモデル クォータによって制限されます。 演習の後半でクォータ制限を超えた場合は、別のリージョンに別のリソースを作成する必要が生じる可能性があります。

1. **[次へ]** を選択し、構成を確認します。 **[作成]** を選択し、プロセスが完了するまで待ちます。
1. プロジェクトが作成されたら、表示されているヒントをすべて閉じて、Azure AI Foundry ポータルのプロジェクト ページを確認します。これは次の画像のようになっているはずです。

    ![Azure AI Foundry ポータルの Azure AI プロジェクトの詳細のスクリーンショット。](./media/ai-foundry-project.png)

## モデルをデプロイする

ソリューションを実装するには、次の 2 つのモデルが必要です。

- 効率的なインデックス作成と処理のためにテキスト データをベクター化する "埋め込み" モデル。**
- ご利用のデータに基づいて、質問に対する自然言語の応答を生成することができるモデル。

1. Azure AI Foundry ポータルで、プロジェクトの左側のナビゲーション ウィンドウの **[マイ アセット]** で、**[モデル + エンドポイント]** ページを選択します。
1. デプロイ モデル ウィザードで **[カスタマイズ]** を選択して、以下の設定で **text-embedding-ada-002** モデルの新しいデプロイを作成します。

    - **デプロイ名**: モデル デプロイの有効な名前**
    - **デプロイの種類**: グローバル標準
    - **モデルのバージョン**: *Select the default version (既定のバージョンの選択)*
    - **接続済み AI リソース**: *以前に作成したリソースを選択します*
    - **1 分あたりのトークンのレート制限 (1,000)**: 50,000 * (または 50,000 未満の場合はサブスクリプションで使用可能な最大値)*
    - **コンテンツ フィルター**: DefaultV2

    > **注**: 現在の AI リソースの場所に、デプロイするモデルで使用可能なクォータがない場合は、新しい AI リソースが作成され、プロジェクトに接続される別の場所を選択するように求められます。

1. **[モデル + エンドポイント]** ページに戻り、前の手順を繰り返して、TPM レート制限が **50,000** (または 50,000 未満の場合はサブスクリプションで使用可能な最大値) の最新バージョンの**グローバル標準**デプロイを使用して、**GPT-4o** モデルをデプロイします。

    > **注**:1 分あたりのトークン数 (TPM) を減らすと、ご利用のサブスクリプション内で使用可能なクォータが過剰に消費されるのを回避するのに役立ちます。 この演習で使用するデータには、50,000 TPM で十分です。

## プロジェクトにデータを追加する

アプリのデータは、架空の旅行代理店 *Margie's Travel* の PDF 形式の旅行パンフレットのセットで構成されています。 それらをプロジェクトに追加しましょう。

1. 新しいブラウザー タブで、[パンフレットの zip 形式アーカイブ](https://github.com/MicrosoftLearning/mslearn-ai-studio/raw/main/data/brochures.zip)を `https://github.com/MicrosoftLearning/mslearn-ai-studio/raw/main/data/brochures.zip` からダウンロードし、ローカル ファイル システム上の「**brochures**」という名前のフォルダーに展開します。
1. Azure AI Foundry ポータル内にあるプロジェクトの左側ナビゲーション ウィンドウ内で、**[マイ アセット]** の下にある **[データ + インデックス]** ページを選択します。
1. **[+ New data]\(+ 新しいデータ\)** を選択します。
1. **[データの追加]** ウィザードで、ドロップダウン メニューを展開して **[Upload files/folders]\(ファイル/フォルダーのアップロード\)** を選択します。
1. **[フォルダーのアップロード]** を選択し、**brochures** フォルダーを選択します。
1. **[次へ]** を選択して、データ名を `brochures` に設定します。
1. フォルダーがアップロードされるまで待ちます。これにはいくつかの .pdf ファイルが含まれています。

## データのインデックスを作成する

これで、ご利用のプロジェクトにデータ ソースを追加したので、それを使用して Azure AI 検索リソース内にインデックスを作成することができます。

1. Azure AI Foundry ポータル内にあるプロジェクトの左側ナビゲーション ウィンドウ内で、**[マイ アセット]** の下にある **[データ + インデックス]** ページを選択します。
1. **[インデックス]** タブで、次の設定で新しいインデックスを追加します。
    - **ソースの場所**:
        - **データ ソース**: Azure AI Foundry のデータ
            - [データ ソース] で **[brochures]** を選択します**
    - **インデックスの構成**:
        - **Azure AI Search サービスの選択**:ご利用の Azure AI 検索リソースへの **[AzureAISearch]** 接続を選択します**
        - **ベクトル インデックス**: `brochures-index`
        - **仮想マシン**:自動選択
    - **[検索設定]**:
        - **[Vector settings]**:ベクトル検索をこの検索リソースに追加します
        - **Azure OpenAI 接続**: *ハブの既定の Azure OpenAI リソースを選択します。*
        - **埋め込みモデル**: text-embedding-ada-002
        - **埋め込みモデルのデプロイ**: ** text-embedding-ada-002 *モデルのデプロイ*

1. ベクトル インデックスを作成し、そのインデックス作成プロセスが完了するまで待ちます。サブスクリプションで使用可能なコンピューティング リソースによっては、しばらく時間がかかる場合があります。

    このインデックス作成操作は、次のジョブで構成されます。

    - ご利用の brochures データ内でテキスト トークンを分解し、塊に分けて、埋め込みます。
    - Azure AI 検索インデックスを作成します。
    - インデックス資産を登録します。

    > **ヒント**: インデックスが作成されるのを待っている間に、ダウンロードしたパンフレットを見て内容を把握しましょう。

## プレイグラウンドでインデックスをテストする

RAG ベースのプロンプト フローでインデックスを使用する前に、それを使用して生成 AI 応答に作用することができるのを確認しましょう。

1. 左側ナビゲーション ウィンドウ内で、**[プレイグラウンド]** ページを選択し、**[チャット]** プレイグラウンドを開きます。
1. [チャット プレイグラウンド] ページの [セットアップ] ウィンドウで、**GPT-4o** モデル デプロイが選択されていることを確認します。 次に、メインの [チャット セッション] パネルで、プロンプト「`Where can I stay in New York?`」を送信します。
1. その応答を確認します。これは、インデックスからのデータを含まない、このモデルからの一般的な回答であるはずです。
1. [セットアップ] ウィンドウで、**"データの追加"** フィールドを展開し、**brochures-index** プロジェクト インデックスを追加して、**[ハイブリッド (ベクトル + キーワード)]** 検索タイプを選択します。

   > **ヒント**: 場合によっては、新しく作成されたインデックスをすぐに使用できない場合があります。 通常はブラウザーの更新で解決しますが、インデックスが見つからない問題がそれでも解決しない場合は、インデックスが認識されるまで待つ必要がある場合があります。

1. インデックスが追加され、チャット セッションが再開された後に、プロンプト「`Where can I stay in New York?`」を再送信します。
1. その応答を確認します。インデックス内のデータに基づいているはずです。

## Azure AI Foundry SDK と Azure OpenAI SDK を使用して RAG クライアント アプリを作成する

作業用インデックスが作成されたので、Azure AI Foundry SDK と Azure OpenAI SDK を使用して、クライアント アプリケーションに RAG パターンを実装できます。 これを実現するコードを簡単な例で見てみましょう。

> **ヒント**: Python または Microsoft C# を使用して RAG ソリューションを開発することを選択できます。 選択した言語の適切なセクションの指示に従います。

### アプリケーション構成を準備する

1. Azure AI Foundry ポータルで、プロジェクトの **[概要]** ページを表示します。
1. **[プロジェクトの詳細]** エリアで、**[プロジェクト接続文字列]** の内容を書き留めます。 この接続文字列を使用して、クライアント アプリケーションでプロジェクトに接続します。
1. 新しいブラウザー タブを開きます (既存のタブで Azure AI Foundry ポータルを開いたままにします)。 新しいブラウザー タブで [Azure portal](https://portal.azure.com) (`https://portal.azure.com`) を開き、メッセージに応じて Azure 資格情報を使用してサインインします。

    ウェルカム通知を閉じて、Azure portal のホーム ページを表示します。

1. ページ上部の検索バーの右側にある **[\>_]** ボタンを使用して、Azure portal に新しい Cloud Shell を作成し、サブスクリプションにストレージがない ***PowerShell*** 環境を選択します。

    Azure portal の下部にあるペインに Cloud Shell のコマンド ライン インターフェイスが表示されます。 作業しやすくするために、このウィンドウのサイズを変更したり最大化したりすることができます。

    > **注**: *Bash* 環境を使用するクラウド シェルを以前に作成した場合は、それを ***PowerShell*** に切り替えます。

1. Cloud Shell ツール バーの **[設定]** メニューで、**[クラシック バージョンに移動]** を選択します (これはコード エディターを使用するのに必要です)。

    **<font color="red">続行する前に、クラシック バージョンの Cloud Shell に切り替えたことを確認します。</font>**

1. Cloud Shell 画面で、次のコマンドを入力して、この演習のコード ファイルを含む GitHub リポジトリを複製します (コマンドを入力するか、クリップボードにコピーしてから、コマンド ラインで右クリックし、プレーンテキストとして貼り付けます)。

    ```
    rm -r mslearn-ai-foundry -f
    git clone https://github.com/microsoftlearning/mslearn-ai-studio mslearn-ai-foundry
    ```

    > **ヒント**: Cloudshell にコマンドを貼り付けると、出力が大量のスクリーン バッファーを占有する可能性があります。 `cls` コマンドを入力して、各タスクに集中しやすくすることで、スクリーンをクリアできます。

1. リポジトリが複製されたら、チャット アプリケーションのコード ファイルを含んだフォルダーに移動します。

    > **注**: 選択したプログラミング言語の手順に従います。

    **Python**

    ```
   cd mslearn-ai-foundry/labfiles/rag-app/python
    ```

    **C#**

    ```
   cd mslearn-ai-foundry/labfiles/rag-app/c-sharp
    ```

1. Cloud Shell コマンド ライン ペインで、次のコマンドを入力して、これから使用するライブラリをインストールします。

    **Python**

    ```
   python -m venv labenv
   ./labenv/bin/Activate.ps1
   pip install python-dotenv azure-ai-projects azure-identity openai
    ```

    **C#**

    ```
   dotnet add package Azure.Identity
   dotnet add package Azure.AI.Projects --prerelease
   dotnet add package Azure.AI.OpenAI --prerelease
    ```
    

1. 次のコマンドを入力して、提供されている構成ファイルを編集します。

    **Python**

    ```
   code .env
    ```

    **C#**

    ```
   code appsettings.json
    ```

    このファイルをコード エディターで開きます。

1. コード ファイルで次のプレースホルダーを置き換えます。 
    - **your_project_connection_string**: プロジェクトの接続文字列 (Azure AI Foundry ポータルでプロジェクトの **[概要]** ページからコピーしたもの) に置き換えます
    - **your_model_deployment** を**GPT-4o** モデル デプロイに割り当てた名前に置き換えます
    - **your_index**: インデックス名 (`brochures-index`) に置き換えます
1. プレースホルダーを置き換えたら、コード エディター内で、**Ctrl + S** コマンドを使用するか、**右クリックして保存**で変更を保存してから、**Ctrl + Q** コマンドを使用するか、**右クリックして終了**で、Cloud Shell コマンド ラインを開いたままコード エディターを閉じます。

### RAG パターンを実装するコードを調べる

1. 次のコマンドを入力して、提供されているコード ファイルを編集します。

    **Python**

    ```
   code rag-app.py
    ```

    **C#**

    ```
   code Program.cs
    ```

1. ファイル内のコードを確認し、次の点に注意します。
    - Azure AI Foundry SDK を使用して、プロジェクトに接続します (プロジェクトの接続文字列を使用)。
    - プロジェクト接続から認証された Azure OpenAI クライアントを作成します。
    - プロジェクトから既定の Azure AI 検索接続を取得し、Azure AI 検索サービスのエンドポイントとキーを決定できるようにします。
    - 適切なシステム メッセージを作成します。
    - プロンプト (ユーザーによる入力に基づいたシステムおよびユーザー メッセージを含む) を Azure OpenAI クライアントに送信し、プロンプトのグラウンディングに使用する Azure AI 検索インデックスに関する情報をさらに追加します。
    - グラウンディングされたプロンプトからの応答を表示します。
    - チャット履歴に応答を追加します。
1. **Ctrl + Q** コマンドを使用して、Cloud Shell コマンド ラインを開いたまま、変更を保存せずにコード エディターを閉じます。

### チャット アプリケーションを実行する

1. Cloud Shell コマンド ライン ペインで、次のコマンドを入力してアプリを実行します。

    **Python**

    ```
   python rag-app.py
    ```

    **C#**

    ```
   dotnet run
    ```

1. メッセージが表示されたら、`Where should I stay in London?` などの質問を入力し、生成 AI モデルからの応答を確認します。

    なお、応答には、回答が見つかったインデックス付きデータを示すソース参照が含まれています。

1. フォローアップの質問を試します (例: `What can I do there?`)。

1. 終了したら、`quit` を入力してプログラムを終了します。 次に、Cloud Shell 画面を閉じます。

## クリーンアップ

不要な Azure のコストとリソース使用を回避するには、この演習でデプロイしたリソースを削除する必要があります。

1. Azure AI Foundry の確認が完了したら、[Azure portal](https://portal.azure.com) (`https://portal.azure.com`) に戻ます。必要に応じて、ご自身の Azure 資格情報を使用してサインインします。 次に、Azure AI 検索と Azure AI リソースをプロビジョニングしたリソース グループ内のリソースを削除します。
