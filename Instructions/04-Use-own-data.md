---
lab:
  title: 独自のデータを使用する生成 AI アプリを作成する
  description: 検索拡張生成 (RAG) モデルを使用して、独自のデータを使ってプロンプトをグラウンディングするチャット アプリを構築する方法について説明します。
---

# 独自のデータを使用する生成 AI アプリを作成する

取得拡張生成 (RAG) は、カスタム データ ソースからのデータを、生成 AI モデルのプロンプトに統合するアプリケーションを構築するために使用される手法です。 RAG は、生成 AI アプリを開発するために一般的に使用されるパターンです。チャット ベースのアプリケーションでは、言語モデルを使用して入力を解釈し、適切な応答を生成します。

この演習では Azure AI Foundry を使用して、カスタム データを生成 AI ソリューションに統合します。

この演習は約 **45** 分かかります。

> **注**: この演習はプレリリース サービスに基づいていますが、このサービスは変更される可能性があります。

## Azure AI Foundry リソースを作成する

Azure AI Foundry リソースの作成から始めましょう。

1. Web ブラウザー内で [Azure portal](https://portal.azure.com) (`https://portal.azure`) を開き、ご自身の Azure 資格情報を使用してサインインします。 初めてサインインしたときに開かれたヒントまたはクイック スタート ペインを閉じます。
1. 次の設定で新しい `Azure AI Foundry` リソースを作成します。
    - **[サブスクリプション]**:"*ご自身の Azure サブスクリプション*"
    - **リソース グループ**: *リソース グループを作成または選択します*
    - **名前**: *Azure AI Foundry リソースの有効な名前*
    - **リージョン**: 次のいずれかのリージョンを選択します。
        - 米国東部 2
        - スウェーデン中部
    - **既定のプロジェクト名**: *プロジェクトの有効な名前*

1. リソースが作成されるのを待ち、Azure portal 内のそのページに移動します。
1. 使用する Azure AI Foundry リソースのページで、**[Go to Azure AI Foundry portal]** を選択します。

## モデルをデプロイする

ソリューションを実装するには、次の 2 つのモデルが必要です。

- 効率的なインデックス作成と処理のためにテキスト データをベクター化する "埋め込み" モデル。**
- ご利用のデータに基づいて、質問に対する自然言語の応答を生成することができるモデル。

1. Azure AI Foundry ポータルで、プロジェクトの左側のナビゲーション ウィンドウの **[マイ アセット]** で、**[モデル + エンドポイント]** ページを選択します。
1. デプロイ モデル ウィザードで **[カスタマイズ]** を選択して、以下の設定で **text-embedding-ada-002** モデルの新しいデプロイを作成します。

    - **デプロイ名**: モデル デプロイの有効な名前**
    - **デプロイの種類**: グローバル標準
    - **モデルのバージョン**: *Select the default version (既定のバージョンの選択)*
    - **接続先 AI リソース**: *以前に作成したリソースを選択します*
    - **1 分あたりのトークンのレート制限 (1,000)**: 50,000 * (または 50,000 未満の場合はサブスクリプションで使用可能な最大値)*
    - **コンテンツ フィルター**: DefaultV2

    > **注**: 現在の AI リソースの場所に、デプロイするモデルで使用可能なクォータがない場合は、新しい AI リソースが作成され、プロジェクトに接続される別の場所を選択するように求められます。

1. **[モデル + エンドポイント]** ページに戻り、前の手順を繰り返し、TPM レート制限が **50K** (または、50K 未満の場合はサブスクリプションで使用可能な最大値) の最新バージョンの **グローバル標準**デプロイを使用して、**gpt-4o** モデルをデプロイします。

    > **注**:1 分あたりのトークン数 (TPM) を減らすと、ご利用のサブスクリプション内で使用可能なクォータが過剰に消費されるのを回避するのに役立ちます。 この演習で使用するデータには、50,000 TPM で十分です。

## プロジェクトにデータを追加する

ご利用のアプリのデータは、架空の旅行代理店 *Margie's Travel* の旅行パンフレット (PDF 形式) のセットで構成されています。 それらをプロジェクトに追加しましょう。

1. 新しいブラウザー タブで、[パンフレットの zip 形式アーカイブ](https://github.com/MicrosoftLearning/mslearn-ai-studio/raw/main/data/brochures.zip)を `https://github.com/MicrosoftLearning/mslearn-ai-studio/raw/main/data/brochures.zip` からダウンロードし、ローカル ファイル システム上の「**brochures**」という名前のフォルダーに展開します。
1. Azure AI Foundry ポータルで、プロジェクトの左側ナビゲーション ウィンドウで **[プレイグラウンド]** を選択し、**[チャット プレイグラウンド]** を選択します。
1. プレイグラウンドの **[セットアップ]** ペインで、**[データを追加する]** セクションを展開し、**[データ ソースの追加]** を選択します。
1. **[データの追加]** ウィザードで、ドロップダウン メニューを展開して **[Upload files]** を選択します。
1. 次の設定で新しい Azure Blob Storage リソースを作成します。
    - **[サブスクリプション]**:"*ご自身の Azure サブスクリプション*"
    - **リソース グループ**: *使用する Azure AI Foundry リソースと同じリソース グループ*
    - **ストレージ アカウント名**: *ストレージ アカウント リソースの有効な名前*
    - **リージョン**: *使用する Azure AI Foundry リソースと同じリージョン*
    - **パフォーマンス**: 標準
    - **冗長性**: LRS
1. リソースを作成し、デプロイが完了するまで待ちます。
1. [Azure AI Foundry] タブに戻り、Azure Blob Storage リソースの一覧を更新し、新しく作成したアカウントを選択します。

    > **注**: Azure OpenAI にリソースにアクセスするためのアクセス許可が必要であるという警告が表示された場合は、**[CORS をオンにする]** を選択します。

1. 次の設定で新しい Azure AI 検索リソースを作成します。
    - **[サブスクリプション]**:"*ご自身の Azure サブスクリプション*"
    - **リソース グループ**: *使用する Azure AI Foundry リソースと同じリソース グループ*
    - **サービス名**: *使用する AI 検索リソースの有効な名前*
    - **リージョン**: *使用する Azure AI Foundry リソースと同じリージョン*
    - **価格レベル**: Basic

1. リソースを作成し、デプロイが完了するまで待ちます。
1. [Azure AI Foundry] タブに戻り、Azure AI 検索リソースの一覧を更新し、新しく作成したアカウントを選択します。
1. インデックスの名前を `brochures-index` に設定します。
1. **[ベクトル検索をこの検索リソースに追加します。]** オプションを有効にし、先ほどデプロイした埋め込みモデルを選択します。 [**次へ**] を選択します。

   >**注**: デプロイされた埋め込みモデルが **[データの追加]** ウィザードで認識されるまでに時間がかかる場合があるため、ベクトル検索オプションを有効にできない場合は、ウィザードをキャンセルして数分待ってから、もう一度やり直してください。

1. 先ほど抽出した **brochures** フォルダーからすべての.pdf ファイルをアップロードし、**[次へ]** を選択します。
1. **[データ管理]** ステップで、検索の種類に **[ハイブリッド (ベクトル + キーワード)]** とチャンク サイズに **[1024]** を選択します。 [**次へ**] を選択します。
1. **[データ接続]** ステップで、認証の種類に **[API キー]** を選択します。 [**次へ**] を選択します。
1. すべての構成ステップを確認し、**[保存して閉じる]** を選択します。
1. インデックス作成プロセスが完了するまで待ちます。サブスクリプションで使用可能なコンピューティング リソースによっては、しばらく時間がかかる場合があります。

    > **ヒント**: インデックスが作成されるのを待っている間に、ダウンロードしたパンフレットを見て内容を把握しましょう。

## プレイグラウンドでインデックスをテストする

RAG ベースのプロンプト フローでインデックスを使用する前に、それを使用して生成 AI 応答に作用することができるのを確認しましょう。

1. [チャット プレイグラウンド] ページの [セットアップ] ペインで、**gpt-4o** モデル デプロイが選択されていることを確認します。 次に、メインの [チャット セッション] パネルで、プロンプト「`Where can I stay in New York?`」を送信します。
1. その応答を確認します。インデックス内のデータに基づいているはずです。

## RAG クライアント アプリを作成する

作業用インデックスが作成されたので、Azure OpenAI SDK を使用して、クライアント アプリケーションに RAG パターンを実装できます。 これを実現するコードを簡単な例で見てみましょう。

> **ヒント**: Python または Microsoft C# を使用して RAG ソリューションを開発することを選択できます。 選択した言語の適切なセクションの指示に従います。

### アプリケーション構成を準備する

1. Azure portal を含むブラウザー タブに戻ります (既存のタブで Azure AI Foundry ポータルを開いたままにします)。
1. ページ上部の検索バーの右側にある **[\>_]** ボタンを使用して、Azure portal に新しい Cloud Shell を作成し、サブスクリプションにストレージがない ***PowerShell*** 環境を選択します。

    Azure portal の下部にあるペインに Cloud Shell のコマンド ライン インターフェイスが表示されます。 作業しやすくするために、このウィンドウのサイズを変更したり最大化したりすることができます。

    > **注**: *Bash* 環境を使用するクラウド シェルを以前に作成した場合は、それを ***PowerShell*** に切り替えます。

1. Cloud Shell ツール バーの **[設定]** メニューで、**[クラシック バージョンに移動]** を選択します (これはコード エディターを使用するのに必要です)。

    **<font color="red">続行する前に、クラシック バージョンの Cloud Shell に切り替えたことを確認します。</font>**

1. Cloud Shell 画面で、次のコマンドを入力して、この演習のコード ファイルを含む GitHub リポジトリをクローンします (コマンドを入力するか、クリップボードにコピーしてから、コマンド ラインで右クリックし、プレーンテキストとして貼り付けます)。

    ```
    rm -r mslearn-ai-foundry -f
    git clone https://github.com/microsoftlearning/mslearn-ai-studio mslearn-ai-foundry
    ```

    > **ヒント**: Cloudshell にコマンドを貼り付けると、出力が大量のスクリーン バッファーを占有する可能性があります。 `cls` コマンドを入力して、各タスクに集中しやすくすることで、スクリーンをクリアできます。

1. リポジトリが複製されたら、チャット アプリケーションのコード ファイルを含んだフォルダーに移動します。

    > **注**: 選択したプログラミング言語の手順に従います。

    **Python**

    ```
   cd mslearn-ai-foundry/labfiles/rag-app/python
    ```

    **C#**

    ```
   cd mslearn-ai-foundry/labfiles/rag-app/c-sharp
    ```

1. Cloud Shell コマンド ライン ペインで、次のコマンドを入力して、OpenAI SDK ライブラリをインストールします。

    **Python**

    ```
   python -m venv labenv
   ./labenv/bin/Activate.ps1
   pip install -r requirements.txt openai
    ```

    **C#**

    ```
   dotnet add package Azure.AI.OpenAI
    ```
    

1. 次のコマンドを入力して、提供されている構成ファイルを編集します。

    **Python**

    ```
   code .env
    ```

    **C#**

    ```
   code appsettings.json
    ```

    このファイルをコード エディターで開きます。

1. コード ファイルで次のプレースホルダーを置き換えます。 
    - **your_openai_endpoint**: Azure AI Foundry ポータルのプロジェクトの **[概要]** ページの Open AI エンドポイント (Azure AI 推論または Azure AI サービス機能ではなく、 **Azure OpenAI** 機能タブを選択してください)。
    - **your_openai_api_key**: Azure AI Foundry ポータルのプロジェクトの **[概要]** ページから Open AI API キー (Azure AI 推論または Azure AI サービス機能ではなく、**Azure OpenAI** 機能タブを選択してください)。
    - **your_chat_model**: Azure AI Foundry ポータルの **[モデル + エンドポイント]** ページから、**gpt-4o** モデル デプロイに割り当てた名前 (既定の名前は `gpt-4o`)。
    - **your_embedding_model**: Azure AI Foundry ポータルの **[モデル + エンドポイント]** ページから、**text-embedding-ada-002** モデル デプロイに割り当てた名前 (既定の名前は `text-embedding-ada-002`)。
    - **your_search_endpoint**: Azure AI 検索リソースの URL。 これは、Azure AI Foundry ポータルの **[管理センター]** にあります。
    - **your_search_api_key**: Azure AI 検索リソースの API キー。 これは、Azure AI Foundry ポータルの **[管理センター]** にあります。
    - **your_index**: Azure AI Foundry ポータルのプロジェクトの **[データとインデックス]** ページのインデックス名に置き換えます (これは `brochures-index` にする必要があります)。
1. プレースホルダーを置き換えたら、コード エディター内で、**Ctrl + S** コマンドを使用するか、**右クリックして保存**で変更を保存してから、**Ctrl + Q** コマンドを使用するか、**右クリックして終了**で、Cloud Shell コマンド ラインを開いたままコード エディターを閉じます。

### RAG パターンを実装するコードを調べる

1. 次のコマンドを入力して、提供されているコード ファイルを編集します。

    **Python**

    ```
   code rag-app.py
    ```

    **C#**

    ```
   code Program.cs
    ```

1. ファイル内のコードを確認し、次の点に注意します。
    - エンドポイント、キー、チャット モデルを使用して Azure OpenAI クライアントを作成します。
    - 旅行関連のチャット ソリューションに適したシステム メッセージを作成します。
    - プロンプト (ユーザーによる入力に基づいたシステムおよびユーザー メッセージを含む) を Azure OpenAI クライアントに送信し、次を追加します。
        - クエリを実行する Azure AI Search インデックスの接続の詳細。
        - クエリのベクター化に使用する埋め込みモデルの詳細\*。
    - グラウンディングされたプロンプトからの応答を表示します。
    - チャット履歴に応答を追加します。

    \**検索インデックスのクエリはプロンプトに基づいており、インデックス付きドキュメント内の関連するテキストを検索するために使用されます。クエリをテキストとして送信するキーワードベースの検索を使用できますが、ベクターベースの検索を使用する方が効率的です。そのため、埋め込みモデルを使用してクエリ テキストを送信する前にベクター化することができます。*

1. **Ctrl + Q** コマンドを使用して、Cloud Shell コマンド ラインを開いたまま、変更を保存せずにコード エディターを閉じます。

### チャット アプリケーションを実行する

1. Cloud Shell コマンド ライン ペインで、次のコマンドを入力してアプリを実行します。

    **Python**

    ```
   python rag-app.py
    ```

    **C#**

    ```
   dotnet run
    ```

1. メッセージが表示されたら、`Where should I go on vacation to see architecture?` などの質問を入力し、生成 AI モデルからの応答を確認します。

    なお、応答には、回答が見つかったインデックス付きデータを示すソース参照が含まれています。

1. フォローアップの質問を試します (例: `Where can I stay there?`)。

1. 終了したら、`quit` を入力してプログラムを終了します。 次に、Cloud Shell 画面を閉じます。

## クリーンアップ

不要な Azure のコストとリソース使用を回避するには、この演習でデプロイしたリソースを削除する必要があります。

1. Azure AI Foundry の確認が完了したら、[Azure portal](https://portal.azure.com) (`https://portal.azure.com`) に戻ます。必要に応じて、ご自身の Azure 資格情報を使用してサインインします。 次に、Azure AI 検索と Azure AI リソースをプロビジョニングしたリソース グループ内のリソースを削除します。
