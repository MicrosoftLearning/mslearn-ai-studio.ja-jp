---
lab:
  title: 独自のデータを使用する生成 AI アプリを作成する
  description: 検索拡張生成 (RAG) モデルを使用して、独自のデータを使ってプロンプトをグラウンディングするチャット アプリを構築する方法について説明します。
---

# 独自のデータを使用する生成 AI アプリを作成する

取得拡張生成 (RAG) は、カスタム データ ソースからのデータを、生成 AI モデルのプロンプトに統合するアプリケーションを構築するために使用される手法です。 RAG は、生成 AI アプリを開発するために一般的に使用されるパターンです。チャット ベースのアプリケーションでは、言語モデルを使用して入力を解釈し、適切な応答を生成します。

この演習では Azure AI Foundry ポータルを使用して、カスタム データを生成 AI プロンプト フローに統合します。

この演習は約 **45** 分かかります。

## "Azure AI 検索" リソースを作成する

生成 AI アプリ ソリューションでは、カスタム データをプロンプト フローに統合します。 この統合をサポートするには、ご利用のデータのインデックス作成に使用する Azure AI 検索リソースが必要です。

1. Web ブラウザー内で [Azure portal](https://portal.azure.com) (`https://portal.azure.com`) を開き、ご自身の Azure 資格情報を使用してサインインします。
1. [ホーム] ページ上で **[+ リソースの作成]** を選択し、「`Azure AI Search`」を検索します。 それから、次の設定で新しい Azure AI 検索リソースを作成します。

    - **[サブスクリプション]**: *Azure サブスクリプションを選択します*
    - **[リソース グループ]**: *リソース グループを選択または作成します*
    - **サービス名**:一意のサービス名を入力します**
    - **[場所]**: *以下のいずれかのリージョンから**ランダム**に選択する*\*
        - オーストラリア東部
        - カナダ東部
        - 米国東部
        - 米国東部 2
        - フランス中部
        - 東日本
        - 米国中北部
        - スウェーデン中部
        - スイス 
    - **価格レベル**: Standard

    > \* 後で、Azure AI 検索リソースと同じリージョンに Azure AI Hub (Azure OpenAI サービスを含む) を作成します。 Azure OpenAI リソースは、リージョンのクォータによってテナント レベルで制限されます。 一覧表示されているリージョンには、この演習で使用されるモデル タイプの既定のクォータが含まれています。 リージョンをランダムに選択すると、テナントを他のユーザーと共有するシナリオで、1 つのリージョンがクォータ制限に達するリスクが軽減されます。 演習の後半でクォータ制限に達した場合は、別のリージョンに別の Azure AI ハブを作成する必要がある可能性があります。

1. Azure AI 検索リソースのデプロイが完了するまでお待ちください。

## Azure AI プロジェクトを作成する

これで Azure AI Foundry プロジェクトと、それをサポートする Azure AI リソースを作成する準備が整いました。

1. Web ブラウザー内で [Azure AI Foundry ポータル](https://ai.azure.com) (`https://ai.azure.com`) を開き、ご自身の Azure 資格情報を使用してサインインします。
1. ホーム ページで、**[+ 作成]** を選択します。
1. **プロジェクトの作成**ウィザードでは、プロジェクトで自動的に作成されるすべての Azure リソースを表示できます。 **[カスタマイズ]** を選択し、Azure AI Search リソースに接続します。

    - **ハブ名**:*一意の名前*
    - **Azure サブスクリプション**:"*ご自身の Azure サブスクリプション*"
    - **[リソース グループ]**: "ご利用の Azure AI 検索リソースを含むリソース グループを選択します"**
    - **[場所]**: *Azure AI 検索リソースと同じ場所*
    - **Azure AI サービスまたは Azure OpenAI に接続**: (新機能) *選択したハブ名が自動入力されます*
    - **Azure AI Search に接続**: *Azure AI Search リソースを選択します*

1. **[次へ]** を選択し、構成を確認します。
1. **[作成]** を選択し、プロセスが完了するまで待ちます。
   
## モデルをデプロイする

ソリューションを実装するには、次の 2 つのモデルが必要です。

- 効率的なインデックス作成と処理のためにテキスト データをベクター化する "埋め込み" モデル。**
- ご利用のデータに基づいて、質問に対する自然言語の応答を生成することができるモデル。

1. Azure AI Foundry ポータルで、プロジェクトの左側のナビゲーション ウィンドウの **[マイ アセット]** で、**[モデル + エンドポイント]** ページを選択します。
1. デプロイ モデル ウィザードで **[カスタマイズ]** を選択して、以下の設定で **text-embedding-ada-002** モデルの新しいデプロイを作成します。

    - **[デプロイ名]**: `text-embedding-ada-002`
    - **デプロイの種類**:Standard
    - **モデルのバージョン**: *Select the default version (既定のバージョンの選択)*
    - **AI リソース**: *以前に作成したリソースを選択します*
    - **1 分あたりのトークン数のレート制限 (1,000 単位)**:5,000
    - **コンテンツ フィルター**: DefaultV2
    - **動的クォータを有効にする**: 無効

    > **注**: 現在の AI リソースの場所に、デプロイするモデルで使用可能なクォータがない場合は、新しい AI リソースが作成され、プロジェクトに接続される別の場所を選択するように求められます。

1. 前の手順を繰り返して、「`gpt-35-turbo-16k`」というデプロイ名で **gpt-35-turbo-16k** モデルをデプロイします。

    > **注**:1 分あたりのトークン数 (TPM) を減らすと、ご利用のサブスクリプション内で使用可能なクォータが過剰に消費されるのを回避するのに役立ちます。 この演習で使用するデータには、5,000 TPM で十分です。

## プロジェクトにデータを追加する

ご利用の Copilot のデータは、架空の旅行代理店 *Margie's Travel* の旅行パンフレット (PDF 形式) のセットで構成されています。 それらをプロジェクトに追加しましょう。

1. [パンフレットの zip 形式のアーカイブ](https://github.com/MicrosoftLearning/mslearn-ai-studio/raw/main/data/brochures.zip)を `https://github.com/MicrosoftLearning/mslearn-ai-studio/raw/main/data/brochures.zip` からダウンロードし、ローカル ファイル システム上の「**brochures**」という名前のフォルダーに展開します。
1. Azure AI Foundry ポータル内にあるプロジェクトの左側ナビゲーション ウィンドウ内で、**[マイ アセット]** の下にある **[データ + インデックス]** ページを選択します。
1. **[+ New data]\(+ 新しいデータ\)** を選択します。
1. **[データの追加]** ウィザードで、ドロップダウン メニューを展開して **[Upload files/folders]\(ファイル/フォルダーのアップロード\)** を選択します。
1. **[フォルダーのアップロード]** を選択し、**brochures** フォルダーを選択します。
1. **[次へ]** を選択して、データ名を `brochures` に設定します。
1. フォルダーがアップロードされるまで待ちます。これにはいくつかの .pdf ファイルが含まれています。

## データのインデックスを作成する

これで、ご利用のプロジェクトにデータ ソースを追加したので、それを使用して Azure AI 検索リソース内にインデックスを作成することができます。

1. Azure AI Foundry ポータル内にあるプロジェクトの左側ナビゲーション ウィンドウ内で、**[マイ アセット]** の下にある **[データ + インデックス]** ページを選択します。
1. **[インデックス]** タブで、次の設定で新しいインデックスを追加します。
    - **ソースの場所**:
        - **データ ソース**: Azure AI Foundry ポータルのデータ
            - [データ ソース] で **[brochures]** を選択します**
    - **インデックスの構成**:
        - **Azure AI Search サービスの選択**:ご利用の Azure AI 検索リソースへの **[AzureAISearch]** 接続を選択します**
        - **ベクトル インデックス**: `brochures-index`
        - **仮想マシン**:自動選択
    - **[検索設定]**:
        - **[Vector settings]**:ベクトル検索をこの検索リソースに追加します
        - **Azure OpenAI 接続**: *ハブの既定の Azure OpenAI リソースを選択します。*
        
1. インデックス作成プロセスが完了するまで待ちます。これには数分かかる場合があります。 このインデックス作成操作は、次のジョブで構成されます。

    - ご利用の brochures データ内でテキスト トークンを分解し、塊に分けて、埋め込みます。
    - Azure AI 検索インデックスを作成します。
    - インデックス資産を登録します。

## インデックスをテストする

RAG ベースのプロンプト フローでインデックスを使用する前に、それを使用して生成 AI 応答に作用することができるのを確認しましょう。

1. 左側ナビゲーション ウィンドウ内で、**[プレイグラウンド]** ページを選択します。
1. [チャット] ページの [セットアップ] ウィンドウで、**gpt-35-turbo-16k** モデル デプロイが選択されていることを確認します。 次に、メインの [チャット セッション] パネルで、プロンプト「`Where can I stay in New York?`」を送信します。
1. その応答を確認します。これは、インデックスからのデータを含まない、このモデルからの一般的な回答であるはずです。
1. [セットアップ] ウィンドウで、**"データの追加"** フィールドを展開し、**brochures-index** プロジェクト インデックスを追加して、**[ハイブリッド (ベクトル + キーワード)]** 検索タイプを選択します。

   > **注**: 一部のユーザーは、新しく作成されたインデックスをすぐには使用できません。 通常はブラウザーの更新で解決しますが、インデックスが見つからない問題がそれでも解決しない場合は、インデックスが認識されるまで待つ必要がある場合があります。

1. インデックスが追加され、チャット セッションが再開された後に、プロンプト「`Where can I stay in New York?`」を再送信します。
1. その応答を確認します。インデックス内のデータに基づいているはずです。

## プロンプト フロー内でインデックスを使用する

ベクター インデックスはご利用の Azure AI Foundry プロジェクト内に保存されており、プロンプト フロー内で簡単に使用することができます。

1. Azure AI Foundry ポータルにおいて、プロジェクトの左側ナビゲーション ウィンドウ内で、**[ビルドとカスタマイズ]** の下にある **[プロンプト フロー]** ページを選択します。
1. ギャラリー内の **[Multi-Round Q&A on Your Data]** サンプルを複製して、新しいプロンプト フローを作成します。 このサンプルの複製を、「`brochure-flow`」という名前のフォルダー内に保存します。
    <details>  
      <summary><b>トラブルシューティングのヒント</b>: アクセス許可エラー</summary>
        <p>新しいプロンプト フローを作成するときにアクセス許可エラーが発生した場合は、次のトラブルシューティングを試してください。</p>
        <ul>
          <li>Azure portal で、AI サービス リソースを選択します。</li>
          <li>[リソース管理] の [ID] タブで、システム割り当てのマネージド ID であることを確認します。</li>
          <li>関連付けられたストレージ アカウントに移動します。 [IAM] ページで、<em>[ストレージ BLOB データ閲覧者]</em> というロールの割り当てを追加します。</li>
          <li><strong>[アクセスの割り当て先]</strong> で、<strong>[マネージド ID]</strong>、<strong>[+ メンバーの選択]</strong> を選択し、<strong>[すべてのシステム割り当てマネージド ID]</strong> を選択して、Azure AI サービス リソースを選択します。</li>
          <li>[確認と割り当て] で新しい設定を保存し、前の手順を繰り返します。</li>
        </ul>
    </details>

1. プロンプト フロー デザイナー ページが開いたら、**[brochure-flow]** を確認します。 そのグラフは、次の画像のようになるはずです。

    ![プロンプト フロー グラフのスクリーンショット](./media/chat-flow.png)

    使用しているサンプル プロンプト フローには、ユーザーがチャット インターフェイスにテキスト入力を繰り返し送信することができる、チャット アプリケーション用のプロンプト ロジックが実装されています。 会話履歴は保持され、繰り返しのたびにコンテキスト内に含まれます。 このプロンプト フローでは、一連の "ツール" を調整して次の操作を行います。**

    - チャット入力に履歴を追加して、質問のコンテキスト化された形式でプロンプトを定義します。
    - 質問に基づいて、インデックスと自分で選んだクエリの種類を使用してコンテキストを取得します。
    - そのインデックスから取得したデータを使用してプロンプト コンテキストを生成し、質問を補足します。
    - システム メッセージを追加し、チャット履歴を構造化して、プロンプト バリアントを作成します。
    - そのプロンプトを言語モデルに送信して、自然言語の応答を生成します。

1. **[コンピューティング セッションの開始]** ボタンを使用して、フローのランタイム コンピューティングを開始します。

    ランタイムが起動するまで待ちます。 これにより、プロンプト フロー用のコンピューティング コンテキストが提供されます。 待っている間に、**[フロー]** タブ内で、フロー内のツールのセクションを確認します。

1. **[入力]** セクションで、入力に次のものが含まれていることを確かめます。
    - **chat_history**
    - **chat_input**

    このサンプル内の既定のチャット履歴には、AI に関するいくつかの会話が含まれています。

1. **[出力]** セクションで、出力に次のものが含まれていることを確かめます。

    - 値 ${chat_with_context.output} の **chat_output**

1. **[modify_query_with_history]** セクション内で、次の設定を選択します (他の設定はそのまま残します)。

    - **[接続]**:*AI ハブの既定の Azure OpenAI リソース*
    - **Api**: chat
    - **deployment_name**: gpt-35-turbo-16k
    - **[response_format]**: {"type":"text"}

1. コンピューティング セッションが開始されるまで待ってから、**[検索]** セクションで、次のパラメーター値を設定します。

    - **mlindex_content**:*空のフィールドを選択して [生成] ペインを開きます*
        - **index_type**:登録済みのインデックス
        - **mlindex_asset_id**: brochures-index:1
    - **queries**: ${modify_query_with_history.output}
    - **query_type**:ハイブリッド (ベクトル + キーワード)
    - **top_k**:2

1. **[generate_prompt_context]** セクション内で、Python スクリプトを確認し、このツールの **[入力]** に次のパラメーターが含まれるようにします。

    - **search_result** *(object)*: ${lookup.output}

1. **[Prompt_variants]** セクション内で、Python スクリプトを確認し、このツールの **[入力]** に次のパラメーターが含まれるようにします。

    - **[contexts]** *(string)*: ${generate_prompt_context.output}
    - **[chat_history]** *(string)*: ${inputs.chat_history}
    - **[chat_input]** *(string)*: ${inputs.chat_input}

1. **[chat_with_context**] セクション内で、次の設定を選択します (他の設定はそのまま残します)。

    - **[接続]**:Default_AzureOpenAI
    - **Api**:チャット
    - **deployment_name**: gpt-35-turbo-16k
    - **[response_format]**: {"type":"text"}

    次に、このツールの **[入力]** に次のパラメーターが含まれるようにします。
    - **[prompt_text]** *(string)*: ${Prompt_variants.output}

1. ツール バー上で **[保存]** ボタンを使用して、プロンプト フロー内でツールに加えた変更を保存します。
1. ツールバー上で **[チャット]** を選択します。 チャット ペインが開き、サンプルの会話履歴と、サンプル値に基づいて既に記入された入力が表示されます。 これらは無視してかまいません。
1. チャット ペイン内で、既定の入力を質問「`Where can I stay in London?`」に置き換えて送信します。
1. その応答を確認します。インデックス内のデータに基づいているはずです。
1. フロー内の各ツールの出力を確認します。
1. チャット ペイン内で、質問「`What can I do there?`」を入力します
1. その応答がインデックス内のデータに基づいていることを確認し、チャット履歴を考慮します ("there" は "in London" と認識されます)。
1. フロー内の各ツールの出力を確認し、フロー内の各ツールがその入力をどのように操作してコンテキスト化されたプロンプトを準備し、適切な応答を取得したのかを確認します。

## フローをデプロイする

これでインデックス付きデータを使用する作業フローが作成されたので、それをサービスとしてデプロイし、Copilot アプリケーションで使用することができます。

> **注**: リージョンとデータセンターの負荷によっては、デプロイに時間がかかる場合や、デプロイを操作するときにエラーがスローされる場合があります。 時間があまりない場合は、遠慮なくデプロイ中に以下のチャレンジ セクションに進んだり、デプロイのテストをスキップしたりしてください。

1. ツールバー上で **[デプロイ]** を選択します。
1. 次の設定でデプロイを作成します。
    - **基本設定**:
        - **エンドポイント**:新規
        - **[エンドポイント名]**:*既定の一意のエンドポイント名を使用する*
        - **デプロイ名**:*既定のデプロイ エンドポイント名を使用する*
        - **仮想マシン**:Standard_DS3_v2
        - **インスタンス数**:3
        - **[推論データ収集]**:オン
    - **[詳細設定]**:
        - 既定の設定を使用します**
1. Azure AI Foundry ポータルのプロジェクトの左側のナビゲーション ウィンドウの **[マイ アセット]** で、**[モデル + エンドポイント]** ページを選択します。
1. "**brochure-endpoint**" エンドポイントの下に "**brochure-endpoint-1**" のデプロイが [成功] と表示されるまでビューを更新し続けます (これには長い時間がかかる場合があります)。**
1. デプロイが成功したら、それを選択します。 次に、その **[テスト]** ページ上でプロンプト「`What is there to do in San Francisco?`」を入力し、その応答を確認します。
1. プロンプト「`Where else could I go?`」を入力し、その応答を確認します。
1. エンドポイントの **[使用]** ページを表示し、エンドポイントのクライアント アプリケーションの構築に使用することができる接続情報とサンプル コードが含まれていることにご注目ください。これにより、このプロンプト フロー ソリューションをカスタム Copilot としてアプリケーションに統合することができます。

## 課題 

Azure AI Foundry ポータルで構築された生成 AI アプリに独自のデータを統合するところまで行いました。さらに詳しく調べてみましょう。

Azure AI Foundry ポータルを使用して新しいデータ ソースを追加し、インデックスを作成し、インデックス付きデータをプロンプト フローと統合してみます。 試すことができるデータ セットは次のとおりです。

- コンピューター上にある (調査) 記事のコレクション。
- 過去の会議で使用したプレゼンテーションのセット。
- [Azure Search サンプル データ](https://github.com/Azure-Samples/azure-search-sample-data) リポジトリで入手できるデータセット。

データ ソースを作成するためにできるだけ多くのデータを集め、プロンプト フローと統合します。 新しいプロンプト フローを試し、選択したデータ セットでのみ応答できるプロンプトを送信します。

## クリーンアップ

不要な Azure のコストとリソース使用を回避するには、この演習でデプロイしたリソースを削除する必要があります。

1. Azure AI Foundry の確認が完了したら、[Azure portal](https://portal.azure.com) (`https://portal.azure.com`) に戻ます。必要に応じて、ご自身の Azure 資格情報を使用してサインインします。 次に、Azure AI 検索と Azure AI リソースをプロビジョニングしたリソース グループ内のリソースを削除します。
