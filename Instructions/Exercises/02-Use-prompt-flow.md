---
lab:
  title: Azure AI Studio でのプロンプト フローの概要
---

# Azure AI Studio でのプロンプト フローの概要

テキストから価値のある情報を抽出することは、固有表現認識 (NER) と呼ばれます。 エンティティとは、特定のテキスト内でユーザーの興味を引くキーワードです。

![エンティティ抽出](./media/get-started-prompt-flow-use-case.gif)

大規模言語モデル (LLM) を使って NER を実行できます。 入力としてテキストを受け取ってエンティティを出力するアプリケーションを作成するには、プロンプト フローで LLM ノードを使うフローを作成できます。

この演習では、Azure AI Studio のプロンプト フローを使って、エンティティの種類とテキストを入力として想定する LLM アプリケーションを作成します。 これは、LLM ノードから Azure OpenAI の GPT モデルを呼び出して、指定されたテキストから必要なエンティティを抽出し、結果をクリーンアップして抽出されたエンティティを出力します。

![演習の概要](./media/get-started-lab.png)

まず、Azure AI Studio でプロジェクトを作成して、必要な Azure リソースを作成する必要があります。 その後、Azure OpenAI サービスを使って GPT モデルをデプロイできます。 必要なリソースが揃ったら、フローを作成できます。 最後に、フローを実行してテストし、サンプル出力を確認します。

## Azure AI Studio でプロジェクトを作成する

最初に、Azure AI Studio プロジェクトと、それをサポートする Azure AI ハブを作成します。

1. Web ブラウザーで [https://ai.azure.com](https://ai.azure.com) を開き、Azure の資格情報を使ってサインインします。
1. **[ビルド]** ページを選んでから、**[+ 新しいプロジェクト]** を選びます。
1. **[新しいプロジェクトの作成]** ウィザードで、次の設定を使ってプロジェクトを作成します。
    - **プロジェクト名**:"プロジェクトの一意の名前"**
    - **[Azure Hub] (Azure ハブ)**: "次の設定で新しいリソースを作成します。"**
        - **[AI Hub name] (AI ハブ名)**: *一意の名前*
        - **[サブスクリプション]**:"*ご自身の Azure サブスクリプション*"
        - **[リソース グループ]**: "新しいリソース グループ"**
        - **[場所]**: *以下のいずれかのリージョンから**ランダム**に選択する*\*
        - オーストラリア東部
        - カナダ東部
        - 米国東部
        - 米国東部 2
        - フランス中部
        - 東日本
        - 米国中北部
        - スウェーデン中部
        - スイス北部
        - 英国南部

    > \* Azure OpenAI リソースは、リージョンのクォータによってテナント レベルで制限されます。 一覧表示されているリージョンには、この演習で使用されるモデル タイプの既定のクォータが含まれています。 リージョンをランダムに選択すると、テナントを他のユーザーと共有するシナリオで、1 つのリージョンがクォータ制限に達するリスクが軽減されます。 演習の後半でクォータ制限に達した場合は、別のリージョンに別のリソースを作成する必要が生じる可能性があります。

1. 構成を確認して、プロジェクトを作成します。
1. プロジェクトが作成されるまで 5 から 10 分待ちます。

## GPT モデルをデプロイする

プロンプト フローで LLM モデルを使うには、まずモデルをデプロイする必要があります。 Azure AI Studio を使うと、フローで使用できる OpenAI モデルをデプロイできます。

1. 左側のナビゲーション ウィンドウの **[コンポーネント]** で、**[デプロイ]** ページを選びます。
1. Azure OpenAI Studio で、**[デプロイ]** ページに移動します。
1. 次の設定で **gpt-35-turbo** モデルの新しいデプロイを作成します。
    - **モデル**: `gpt-35-turbo`
    - **モデルのバージョン**: *既定値のままにします*
    - **[デプロイ名]**: `gpt-35-turbo`
    - 既定のコンテンツ フィルターを使って、1 分あたりのトークン数 (TPM) を **5K** に制限するには、**[詳細設定]** オプションを設定します。

LLM モデルがデプロイされたので、デプロイされたモデルを呼び出すフローを Azure AI Studio で作成できます。

## Azure AI Studio でフローを作成して実行する

必要なリソースがすべてプロビジョニングされたので、フローを作成できます。

### 新しいフローの作成

テンプレートで新しいフローを作成するには、開発するフローの種類を 1 つ選択できます。

1. 左側のナビゲーション ウィンドウの **[ツール]** で、**[プロンプト フロー]** を選びます。
1. **[+ 作成]** を選んで、新しいフローを作成します。
1. 新しい**標準フロー**を作成し、フォルダー名として「`entity-recognition`」と入力します。

1 つの入力、2 つのノード、1 つの出力を含む標準フローが自動的に作成されます。 フローを更新して、2 つの入力を受け取り、エンティティを抽出し、LLM ノードからの出力をクリーンアップし、出力としてエンティティを返すようにします。

### 自動ランタイムを開始する

フローをテストするには、コンピューティングが必要です。 必要なコンピューティングは、ランタイムを通じて利用できるようになります。

1. `entity-recognition` という名前で新しいフローを作成すると、スタジオでそのフローが開きます。
1. 上部のバーで **[ランタイムの選択]** フィールドを選びます。
1. **[自動ランタイム]** ボックスの一覧で **[開始]** を選んで、自動ランタイムを開始します。
1. ランタイムが起動するまで待ちます。

### 入力を構成する

作成するフローは、テキストと、テキストから抽出するエンティティの種類という、2 つの入力を受け取ります。

1. **[入力]** には、名前が `topic` で型が `string` の 1 つの入力が構成されています。 既存の入力を変更し、次の設定で更新します。
    - **名前**: `entity_type`
    - **型**: `string`
    - **値**: `job title`
1. **[入力の追加]** を選びます。
1. 2 番目の入力を構成して、次のように設定します。
    - **名前**: `text`
    - **型**: `string`
    - **値**: `The software engineer is working on a new update for the application.`

### LLM ノードを構成する

標準フローには、LLM ツールを使うノードが既に含まれています。 フローの概要でノードを見つけることができます。 既定のプロンプトでは、ジョークを求められます。 前のセクションで指定した 2 つの入力に基づいてエンティティを抽出するように、LLM ノードを更新します。

1. `joke` という名前の **LLM ノード**に移動します。
1. 名前を `NER_LLM` に置き換えます
1. **[接続]** で、`Default_AzureOpenAI` 接続を選びます。
1. **deployment_name** では、デプロイした `gpt-35-turbo` モデルを選びます。
1. プロンプト フィールドを次のコードに置き換えます。

   ```yml
   {% raw %}
   system:

   Your task is to find entities of a certain type from the given text content.
   If there're multiple entities, please return them all with comma separated, e.g. "entity1, entity2, entity3".
   You should only return the entity list, nothing else.
   If there's no such entity, please return "None".

   user:
   
   Entity type: {{entity_type}}
   Text content: {{text}}
   Entities:
   {% endraw %}
   ```

1. **[入力の検証と解析]** を選びます。
1. LLM ノードの **[入力]** セクションで、次のように構成します。
    - `entity_type` では、値 `${inputs.entity_type}` を選びます。
    - `text` では、値 `${inputs.text}` を選びます。

これで、この LLM ノードは、エンティティの種類とテキストを入力として受け取り、指定したプロンプトにそれを含めて、デプロイされたモデルに要求を送信するようになります。

### Python ノードを構成する

モデルの結果から重要な情報のみを抽出するには、Python ツールを使って LLM ノードの出力をクリーンアップできます。

1. `echo` という名前の Python ノードに移動します。
1. 名前を `cleansing` に置き換えます。
1.  のコードを次のように置き換えます。

   ```python
   from typing import List
   from promptflow import tool
    
    
   @tool
   def cleansing(entities_str: str) -> List[str]:
       # Split, remove leading and trailing spaces/tabs/dots
       parts = entities_str.split(",")
       cleaned_parts = [part.strip(" \t.\"") for part in parts]
       entities = [part for part in cleaned_parts if len(part) > 0]
       return entities
    
   ```

1. **[入力の検証と解析]** を選びます。
1. Python ノードの **[入力]** セクションで、`entities_str` の値を `${NER_LLM.output}` に設定します。

### 出力を構成する

最後に、フロー全体の出力を構成できます。 フローで必要な出力は 1 つだけで、それを抽出されたエンティティにする必要があります。

1. フローの **[出力]** に移動します。
1. **名前**には、`entities`を入力します。
1. **[値]** で、`${cleansing.output}` を選びます。

### フローを実行する

フローの開発が済んだので、それを実行してテストできます。 入力に既定値を追加したので、スタジオでフローを簡単にテストできます。

1. **[実行]** を選んでフローをテストします。
1. 実行が完了するまで待ちます。
1. **[出力の表示]** を選びます。 既定の入力に対する出力を示すポップアップが表示されます。 必要に応じて、ログを調べることもできます。

## Azure リソースを削除する

Azure AI Studio を調べ終わったら、Azure の不要なコストを避けるため、作成したリソースを削除する必要があります。

- [Azure portal](https://portal.azure.com) (`https://portal.azure.com`) に移動します。
- Azure portal の **[ホーム]** ページで、**[リソース グループ]** を選択します。
- この演習のために作成したリソース グループを選びます。
- リソース グループの **[概要]** ページの上部で、**[リソース グループの削除]** を選択します。
- リソース グループ名を入力して、削除することを確認し、**[削除]** を選択します。
