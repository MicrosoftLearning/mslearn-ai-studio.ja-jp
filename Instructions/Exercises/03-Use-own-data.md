---
lab:
  title: 独自のデータを使用するカスタム Copilot を作成する
---

# 独自のデータを使用するカスタム Copilot を作成する

取得拡張生成 (RAG) は、カスタム データ ソースからのデータを、生成 AI モデルのプロンプトに統合するアプリケーションを構築するために使用される手法です。 RAG は、カスタム *Copilot* を開発するために一般的に使用されるパターンです。チャット ベースのアプリケーションでは、言語モデルを使用して入力を解釈し、適切な応答を生成します。

この演習では Azure AI Studio を使用して、カスタム データを生成 AI プロンプト フローに統合します。

> **注**:Azure AI Studio は執筆時点でプレビュー段階にあり、現在活発に開発されています。 このサービスの一部の要素は正確に説明されていない場合があり、一部の機能は期待どおりに動作しない場合があります。

この演習は約 **45** 分かかります。

## "Azure AI 検索" リソースを作成する

Copilot ソリューションでは、カスタム データをプロンプト フローに統合します。 この統合をサポートするには、ご利用のデータのインデックス作成に使用する Azure AI 検索リソースが必要です。

1. Web ブラウザー内で [Azure portal](https://portal.azure.com) (`https://portal.azure.com`) を開き、ご自身の Azure 資格情報を使用してサインインします。
1. [ホーム] ページ上で **[+ リソースの作成]** を選択し、「`Azure AI Search`」を検索します。 それから、次の設定で新しい Azure AI 検索リソースを作成します。

    - **[サブスクリプション]**: *Azure サブスクリプションを選択します*
    - **[リソース グループ]**: *リソース グループを選択または作成します*
    - **サービス名**:一意のサービス名を入力します**
    - **[場所]**: 任意の使用可能な場所を選択します**
    - **価格レベル**: Standard

1. Azure AI 検索リソースのデプロイが完了するまでお待ちください。

## Azure AI プロジェクトを作成する

これで Azure AI Studio プロジェクトと、それをサポートする Azure AI リソースを作成する準備が整いました。

1. Web ブラウザー内で [Azure AI Studio](https://ai.azure.com) (`https://ai.azure.com`) を開き、ご自身の Azure 資格情報を使用してサインインします。
1. **[ビルド]** ページ上で、**[+ New AI project]\(+ 新しい AIプロジェクト\)** を選択します。 次に、**[作業の開始]** ウィザードで、次の設定を使用してプロジェクトを作成します。

    - **プロジェクト名**:"プロジェクトの一意の名前"**
    - **AI ハブ**:次の設定で新しいリソースを作成します。**

        - **[AI hub name]**:*一意の名前*
        - **Azure サブスクリプション**:"*ご自身の Azure サブスクリプション*"
        - **[リソース グループ]**: "ご利用の Azure AI 検索リソースを含むリソース グループを選択します"**
        - **[場所]**: Azure AI 検索リソースと同じ場所 (または地理的に近い場所)**
        - **Azure OpenAI**:(新規) "選択したハブ名がオートフィルされます"**
        - **[Azure AI 検索]**:Azure AI 検索リソースを選択します**

1. プロジェクトが作成されるまで待ちます。

## モデルをデプロイする

ソリューションを実装するには、次の 2 つのモデルが必要です。

- 効率的なインデックス作成と処理のためにテキスト データをベクター化する "埋め込み" モデル。**
- ご利用のデータに基づいて、質問に対する自然言語の応答を生成することができるモデル。

1. Azure AI Studio 内のプロジェクトの左側ナビゲーション ウィンドウで、**[コンポーネント]** の下にある **[デプロイ]** ページを選択します。
1. 以下の設定を使用して、**text-embedding-ada-002** モデルの新しいデプロイ (**リアルタイム エンドポイント**を使用) を作成します。

    - **[デプロイ名]**: `text-embedding-ada-002`
    - **モデルのバージョン**: *既定値*
    - **詳細オプション**:
        - **コンテンツ フィルター**:*既定値*
        - **1 分あたりのトークン数のレート制限**: `5K`

> **注**:1 分あたりのトークン数 (TPM) を減らすと、ご利用のサブスクリプション内で使用可能なクォータが過剰に消費されるのを回避するのに役立ちます。 この演習で使用するデータには、5,000 TPM で十分です。

## プロジェクトにデータを追加する

ご利用の Copilot のデータは、架空の旅行代理店 *Margie's Travel* の旅行パンフレット (PDF 形式) のセットで構成されています。 それらをプロジェクトに追加しましょう。

1. [パンフレットの zip 形式のアーカイブ](https://github.com/MicrosoftLearning/mslearn-ai-studio/raw/main/data/brochures.zip)を `https://github.com/MicrosoftLearning/mslearn-ai-studio/raw/main/data/brochures.zip` からダウンロードし、ローカル ファイル システム上の「**brochures**」という名前のフォルダーに展開します。
1. Azure AI Studio 内にあるプロジェクトの左側ナビゲーション ウィンドウ内で、**[コンポーネント]** の下にある **[データ]** ページを選択します。
1. **[+ New data]\(+ 新しいデータ\)** を選択します。
1. **[データの追加]** ウィザードで、ドロップダウン メニューを展開して **[Upload files/folders]\(ファイル/フォルダーのアップロード\)** を選択します。
1. **[フォルダーのアップロード]** を選択し、**brochures** フォルダーを選択します。
1. データ名を **brochures** に設定します。

## データのインデックスを作成する

これで、ご利用のプロジェクトにデータ ソースを追加したので、それを使用して Azure AI 検索リソース内にインデックスを作成することができます。

1. Azure AI Studio 内にあるプロジェクトの左側ナビゲーション ウィンドウ内で、**[コンポーネント]** の下にある **[インデックス]** ページを選択します。
1. 次の設定で新しいインデックスを追加します。
    - **[ソース データ]**:
        - **データ ソース**:既存のプロジェクト データを使用します
            - [データ ソース] で **[brochures]** を選択します**
    - **[インデックス ストレージ]**:
        - ご利用の Azure AI 検索リソースへの **[AzureAISearch]** 接続を選択します**
    - **[検索設定]**:
        - **[Vector settings]**:ベクトル検索をこの検索リソースに追加します
        - **[Azure OpenAI リソース]**:Default_AzureOpenAI
        - 埋め込みモデルがデプロイされることを確認します**
    - **[インデックス設定]**:
        - **[インデックス名]**: brochures-index
        - **仮想マシン**:自動選択
1. インデックスの準備が整うのを待ちます。これには数分かかる場合があります。 このインデックス作成操作は、次のジョブで構成されます。

    - ご利用の brochures データ内でテキスト トークンを分解し、塊に分けて、埋め込みます。
    - インデックスを更新する。
    - インデックス資産を登録します。

## インデックスをテストする

RAG ベースのプロンプト フローでインデックスを使用する前に、それを使用して生成 AI 応答に作用することができるのを確認しましょう。

1. 左側ナビゲーション ウィンドウ内で、**[ツール]** の下にある **[プレイグラウンド]** ページを選択します。
1. [プレイグラウンド] ページ上の **[構成]** ペイン内で、**[gpt-35-turbo]** モデル デプロイが選択されていることを確認します。 次に、**[チャット セッション]** ペイン内で、プロンプト「`Where can I stay in New York?`」を送信します
1. その応答を確認します。これは、インデックスからのデータを含まない、このモデルからの一般的な回答であるはずです。
1. **[アシスタントのセットアップ]** ペイン内で、**[データを追加する]** を選択し、次の設定でデータ ソースを追加します。

    - **データ ソース**:
        - **[Select data source]**:Azure AI Search
        - **[サブスクリプション]**:"*ご自身の Azure サブスクリプション*"
        - **[Azure AI Search Service]**:ご利用の Azure AI 検索リソース**
        - **[Azure AI Search index]**: brochures-index
        - **ベクトル検索を追加する**:<u>未</u>選択
        - **カスタム フィールド マッピングを使用する**:オン
        - 使用発生を確認するチェック ボックスをオンにします。
    - **[Data field mapping]**:
        - **[Content data]**: コンテンツ
        - **[File name]**: filepath
        - **[Title]**: タイトル
        - **[URL]**: url
    - ** データ管理**：
        - **search type**:Keyword

1. データ ソースが追加され、チャット セッションが再開された後に、プロンプト「`Where can I stay in New York?`」を再送信します
1. その応答を確認します。インデックス内のデータに基づいているはずです。

## プロンプト フロー内でインデックスを使用する

ベクター インデックスはご利用の Azure AI Studio プロジェクト内に保存されており、プロンプト フロー内で簡単に使用することができます。

1. Azure AI Studio 内にあるプロジェクトの左側ナビゲーション ウィンドウ内で、**[コンポーネント]** の下にある **[データ]** を選択します。
1. 前に作成したインデックスを含む ''**brochures-index**" フォルダーを選択します。
1. インデックスの **[データ リンク]** セクションで、**[データ接続 URI]** の値をクリップボードにコピーします (`azureml://subscriptions/xxx/resourcegroups/xxx/workspaces/xxx/datastores/workspaceblobstore/paths/azureml/xxx/index/` のようになるはずです)。 プロンプト フロー内でインデックスに接続するために、この URI が必要になります。
1. プロジェクトの左側ナビゲーション ウィンドウ内で、**[ツール]** の下にある **[プロンプト フロー]** ページを選択します。
1. ギャラリー内の **[Multi-Round Q&A on Your Data]** サンプルを複製して、新しいプロンプト フローを作成します。 このサンプルの複製を、「`brochure-flow`」という名前のフォルダー内に保存します。
1. プロンプト フロー デザイナー ページが開いたら、**[brochure-flow]** を確認します。 そのグラフは、次の画像のようになるはずです。

    ![プロンプト フロー グラフのスクリーンショット](./media/chat-flow.png)

    使用しているサンプル プロンプト フローには、ユーザーがチャット インターフェイスにテキスト入力を繰り返し送信することができる、チャット アプリケーション用のプロンプト ロジックが実装されています。 会話履歴は保持され、繰り返しのたびにコンテキスト内に含まれます。 このプロンプト フローでは、一連の "ツール" を調整して次の操作を行います。**

    - チャット入力に履歴を追加して、質問のコンテキスト化された形式でプロンプトを定義します。
    - 質問に基づいて、インデックスと自分で選んだクエリの種類を使用してコンテキストを取得します。
    - そのインデックスから取得したデータを使用してプロンプト コンテキストを生成し、質問を補足します。
    - システム メッセージを追加し、チャット履歴を構造化して、プロンプト バリアントを作成します。
    - そのプロンプトを言語モデルに送信して、自然言語の応答を生成します。

1. **[ランタイム]** 一覧の中で、**[開始]** を選択して自動ランタイムを開始します。

    次に、その開始を待ちます。 これにより、プロンプト フロー用のコンピューティング コンテキストが提供されます。 待っている間に、**[フロー]** タブ内で、フロー内のツールのセクションを確認します。

1. **[入力]** セクションで、入力に次のものが含まれていることを確かめます。
    - **chat_history**
    - **chat_input**

    このサンプル内の既定のチャット履歴には、AI に関するいくつかの会話が含まれています。

1. **[出力]** セクションで、出力に次のものが含まれていることを確かめます。

    - **chat_output** (値は `${chat_with_context.output}`)

1. **[modify_query_with_history]** セクション内で、次の設定を選択します (他の設定はそのまま残します)。

    - **Connection**: `Default_AzureOpenAI`
    - **Api**: `chat`
    - **deployment_name**: `gpt-35-turbo`
    - **response_format**: `{"type":"text"}`

1. **[検索]** セクションで、次のパラメーター値を設定します。

    - **mlindex_content**:*空のフィールドを選択して [生成] ペインを開きます*
        - **index_type**: `MLIndex file from path`
        - **mlindex_path**:*ベクトル インデックスの URI を貼り付けます*
    - **queries**: `${modify_query_with_history.output}`
    - **query_type**: `Hybrid (vector + keyword)`
    - **top_k**:2

1. **[generate_prompt_context]** セクション内で、Python スクリプトを確認し、このツールの **[入力]** に次のパラメーターが含まれるようにします。

    - **[search_result]** *(object)*: ${search_question_from_indexed_docs.output}

1. **[Prompt_variants]** セクション内で、Python スクリプトを確認し、このツールの **[入力]** に次のパラメーターが含まれるようにします。

    - **[contexts]** *(string)*: ${generate_prompt_context.output}
    - **[chat_history]** *(string)*: ${inputs.chat_history}
    - **[chat_input]** *(string)*: ${inputs.chat_input}

1. **[chat_with_context**] セクション内で、次の設定を選択します (他の設定はそのまま残します)。

    - **[接続]**:Default_AzureOpenAI
    - **Api**:チャット
    - **[deployment_name]**: gpt-35-turbo
    - **[response_format]**: {"type":"text"}

    次に、このツールの **[入力]** に次のパラメーターが含まれるようにします。
    - **[prompt_text]** *(string)*: ${Prompt_variants.output}

1. ツール バー上で **[保存]** ボタンを使用して、プロンプト フロー内でツールに加えた変更を保存します。
1. ツールバー上で **[チャット]** を選択します。 チャット ペインが開き、サンプルの会話履歴と、サンプル値に基づいて既に記入された入力が表示されます。 これらは無視してかまいません。
1. チャット ペイン内で、既定の入力を質問「`Where can I stay in London?`」に置き換えて送信します。
1. その応答を確認します。インデックス内のデータに基づいているはずです。
1. フロー内の各ツールの出力を確認します。
1. チャット ペイン内で、質問「`What can I do there?`」を入力します
1. その応答がインデックス内のデータに基づいていることを確認し、チャット履歴を考慮します ("there" は "in London" と認識されます)。
1. フロー内の各ツールの出力を確認し、フロー内の各ツールがその入力をどのように操作してコンテキスト化されたプロンプトを準備し、適切な応答を取得したのかを確認します。

## フローをデプロイする

これでインデックス付きデータを使用する作業フローが作成されたので、それをサービスとしてデプロイし、Copilot アプリケーションで使用することができます。

1. ツールバー上で **[デプロイ]** を選択します。
1. 次の設定でデプロイを作成します。
    - **基本設定**:
        - **エンドポイント**:新規
        - **[エンドポイント名]**: brochure-endpoint
        - **[デプロイ名]**: brochure-endpoint-1
        - **仮想マシン**:Standard_DS3_v2
        - **インスタンス数**:3
        - **[推論データ収集]**:オン
        - **[Application Insights 診断]**:オン
    - **[詳細設定]**:
        - 既定の設定を使用します**
1. Azure AI Studio 内にあるプロジェクトの左側ナビゲーション ウィンドウ内で、**[コンポーネント]** の下にある **[デプロイ]** ページを選択します。
1. **[brochure-endpoint]** の下で **[brochure-endpoint-1]** のデプロイが [成功] と表示されるまでビューを更新し続けます (これには時間がかかる場合があります)。**
1. デプロイが成功したら、それを選択します。 次に、その **[テスト]** ページ上でプロンプト「`What is there to do in San Francisco?`」を入力し、その応答を確認します。
1. プロンプト「`Where else could I go?`」を入力し、その応答を確認します。
1. エンドポイントの **[使用]** ページを表示し、エンドポイントのクライアント アプリケーションの構築に使用することができる接続情報とサンプル コードが含まれていることにご注目ください。これにより、このプロンプト フロー ソリューションをカスタム Copilot としてアプリケーションに統合することができます。

## クリーンアップ

不要な Azure のコストとリソース使用を回避するには、この演習でデプロイしたリソースを削除する必要があります。

1. Azure AI Studio 内で、**[ビルド]** ページを表示します。 次に、この演習で作成したプロジェクトを選択し、**[プロジェクトの削除]** ボタンを使用してそれを削除します。 すべてのコンポーネントを削除するには数分かかる場合があります。
1. Azure AI Studio の確認が完了したら、[Azure portal](https://portal.azure.com) (`https://portal.azure.com`) に戻ます。必要に応じて、ご自身の Azure 資格情報を使用してサインインします。 次に、Azure AI 検索と Azure AI リソース用に作成したリソース グループを削除します。
